{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f175dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d82cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('split_data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e157c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be458af6",
   "metadata": {},
   "source": [
    "### Autoencoder for Unsupervised Representation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_ae = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",         \n",
    "    patience=5,                 \n",
    "    restore_best_weights=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb6d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(X_train_scaled.shape[1],))\n",
    "encoded = layers.Dense(32, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dense(16, activation=\"relu\")(encoded)\n",
    "encoded_output = layers.Dense(8, activation=\"relu\")(encoded)\n",
    "\n",
    "decoded = layers.Dense(16, activation=\"relu\")(encoded_output)\n",
    "decoded = layers.Dense(32, activation=\"relu\")(decoded)\n",
    "decoded_output = layers.Dense(X_train_scaled.shape[1], activation=\"linear\")(decoded)\n",
    "\n",
    "autoencoder = keras.Model(inputs=input_layer, outputs=decoded_output)\n",
    "encoder = keras.Model(inputs=input_layer, outputs=encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8481906",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss='mean_squared_error',\n",
    "  metrics=['mean_absolute_error', 'mean_squared_error']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437c776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.6368 - mean_absolute_error: 0.5073 - mean_squared_error: 0.6368 - val_loss: 0.3014 - val_mean_absolute_error: 0.3463 - val_mean_squared_error: 0.3014\n",
      "Epoch 2/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.3069 - mean_absolute_error: 0.3450 - mean_squared_error: 0.3069 - val_loss: 0.2199 - val_mean_absolute_error: 0.3052 - val_mean_squared_error: 0.2199\n",
      "Epoch 3/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.2258 - mean_absolute_error: 0.3086 - mean_squared_error: 0.2258 - val_loss: 0.1885 - val_mean_absolute_error: 0.2899 - val_mean_squared_error: 0.1885\n",
      "Epoch 4/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1925 - mean_absolute_error: 0.2878 - mean_squared_error: 0.1925 - val_loss: 0.1737 - val_mean_absolute_error: 0.2779 - val_mean_squared_error: 0.1737\n",
      "Epoch 5/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1686 - mean_absolute_error: 0.2667 - mean_squared_error: 0.1686 - val_loss: 0.1628 - val_mean_absolute_error: 0.2594 - val_mean_squared_error: 0.1628\n",
      "Epoch 6/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1619 - mean_absolute_error: 0.2602 - mean_squared_error: 0.1619 - val_loss: 0.1854 - val_mean_absolute_error: 0.2682 - val_mean_squared_error: 0.1854\n",
      "Epoch 7/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1651 - mean_absolute_error: 0.2601 - mean_squared_error: 0.1651 - val_loss: 0.1675 - val_mean_absolute_error: 0.2604 - val_mean_squared_error: 0.1675\n",
      "Epoch 8/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1596 - mean_absolute_error: 0.2549 - mean_squared_error: 0.1596 - val_loss: 0.1508 - val_mean_absolute_error: 0.2493 - val_mean_squared_error: 0.1508\n",
      "Epoch 9/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1585 - mean_absolute_error: 0.2530 - mean_squared_error: 0.1585 - val_loss: 0.1497 - val_mean_absolute_error: 0.2482 - val_mean_squared_error: 0.1497\n",
      "Epoch 10/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1534 - mean_absolute_error: 0.2491 - mean_squared_error: 0.1534 - val_loss: 0.1475 - val_mean_absolute_error: 0.2437 - val_mean_squared_error: 0.1475\n",
      "Epoch 11/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1554 - mean_absolute_error: 0.2479 - mean_squared_error: 0.1554 - val_loss: 0.1425 - val_mean_absolute_error: 0.2408 - val_mean_squared_error: 0.1425\n",
      "Epoch 12/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1468 - mean_absolute_error: 0.2422 - mean_squared_error: 0.1468 - val_loss: 0.1422 - val_mean_absolute_error: 0.2407 - val_mean_squared_error: 0.1422\n",
      "Epoch 13/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1427 - mean_absolute_error: 0.2389 - mean_squared_error: 0.1427 - val_loss: 0.1421 - val_mean_absolute_error: 0.2363 - val_mean_squared_error: 0.1421\n",
      "Epoch 14/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1448 - mean_absolute_error: 0.2404 - mean_squared_error: 0.1448 - val_loss: 0.1353 - val_mean_absolute_error: 0.2318 - val_mean_squared_error: 0.1353\n",
      "Epoch 15/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1389 - mean_absolute_error: 0.2347 - mean_squared_error: 0.1389 - val_loss: 0.1393 - val_mean_absolute_error: 0.2321 - val_mean_squared_error: 0.1393\n",
      "Epoch 16/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1398 - mean_absolute_error: 0.2349 - mean_squared_error: 0.1398 - val_loss: 0.1329 - val_mean_absolute_error: 0.2268 - val_mean_squared_error: 0.1329\n",
      "Epoch 17/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1436 - mean_absolute_error: 0.2377 - mean_squared_error: 0.1436 - val_loss: 0.1333 - val_mean_absolute_error: 0.2315 - val_mean_squared_error: 0.1333\n",
      "Epoch 18/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.1361 - mean_absolute_error: 0.2314 - mean_squared_error: 0.1361 - val_loss: 0.1355 - val_mean_absolute_error: 0.2252 - val_mean_squared_error: 0.1355\n",
      "Epoch 19/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1416 - mean_absolute_error: 0.2337 - mean_squared_error: 0.1416 - val_loss: 0.1293 - val_mean_absolute_error: 0.2233 - val_mean_squared_error: 0.1293\n",
      "Epoch 20/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1302 - mean_absolute_error: 0.2257 - mean_squared_error: 0.1302 - val_loss: 0.1297 - val_mean_absolute_error: 0.2264 - val_mean_squared_error: 0.1297\n",
      "Epoch 21/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1315 - mean_absolute_error: 0.2268 - mean_squared_error: 0.1315 - val_loss: 0.1260 - val_mean_absolute_error: 0.2195 - val_mean_squared_error: 0.1260\n",
      "Epoch 22/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1283 - mean_absolute_error: 0.2235 - mean_squared_error: 0.1283 - val_loss: 0.1405 - val_mean_absolute_error: 0.2417 - val_mean_squared_error: 0.1405\n",
      "Epoch 23/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1349 - mean_absolute_error: 0.2282 - mean_squared_error: 0.1349 - val_loss: 0.2099 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.2099\n",
      "Epoch 24/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1342 - mean_absolute_error: 0.2291 - mean_squared_error: 0.1342 - val_loss: 0.1336 - val_mean_absolute_error: 0.2261 - val_mean_squared_error: 0.1336\n",
      "Epoch 25/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1254 - mean_absolute_error: 0.2209 - mean_squared_error: 0.1254 - val_loss: 0.1263 - val_mean_absolute_error: 0.2191 - val_mean_squared_error: 0.1263\n",
      "Epoch 26/30\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.1256 - mean_absolute_error: 0.2197 - mean_squared_error: 0.1256 - val_loss: 0.1294 - val_mean_absolute_error: 0.2246 - val_mean_squared_error: 0.1294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d1e202df00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "autoencoder.fit(\n",
    "    X_train_scaled, X_train_scaled,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop_ae],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772e9f2",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aaf5a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2850/2850\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step\n"
     ]
    }
   ],
   "source": [
    "X_train_embed = encoder.predict(X_train_scaled)\n",
    "X_test_embed  = encoder.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc9181",
   "metadata": {},
   "source": [
    "### Clustering on Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eff9a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "train_clusters = kmeans.fit_predict(X_train_embed)\n",
    "test_clusters  = kmeans.predict(X_test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af85a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster as a new feature\n",
    "\n",
    "X_train_final = np.concatenate([X_train_scaled, X_train_embed, train_clusters.reshape(-1,1)], axis=1)\n",
    "X_test_final  = np.concatenate([X_test_scaled,  X_test_embed,  test_clusters.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bfcfd",
   "metadata": {},
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d3b34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        weights = tf.nn.softmax(inputs, axis=1)\n",
    "        return inputs * weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8e2f0",
   "metadata": {},
   "source": [
    "### Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33350d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",         \n",
    "    patience=10,               \n",
    "    restore_best_weights=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805df1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\anaconda\\envs\\tf-cpu-env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_final.shape[1],)),\n",
    "    AttentionLayer(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"linear\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d8904a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ attention_layer                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ attention_layer                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,424\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,201</span> (200.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,201\u001b[0m (200.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,201</span> (200.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,201\u001b[0m (200.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efe4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\", \"mse\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a50d82cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 432.2245 - mae: 16.3185 - mse: 432.2245 - val_loss: 343.3291 - val_mae: 14.3038 - val_mse: 343.3291\n",
      "Epoch 2/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 321.8345 - mae: 13.8145 - mse: 321.8345 - val_loss: 317.4845 - val_mae: 13.6712 - val_mse: 317.4845\n",
      "Epoch 3/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 306.8105 - mae: 13.5181 - mse: 306.8105 - val_loss: 318.5405 - val_mae: 13.7108 - val_mse: 318.5405\n",
      "Epoch 4/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 302.5040 - mae: 13.2417 - mse: 302.5040 - val_loss: 298.5368 - val_mae: 13.2213 - val_mse: 298.5368\n",
      "Epoch 5/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 297.3577 - mae: 13.1901 - mse: 297.3577 - val_loss: 306.0950 - val_mae: 13.3661 - val_mse: 306.0950\n",
      "Epoch 6/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 293.4340 - mae: 13.0084 - mse: 293.4340 - val_loss: 294.8284 - val_mae: 13.0897 - val_mse: 294.8284\n",
      "Epoch 7/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 292.9945 - mae: 13.0510 - mse: 292.9945 - val_loss: 303.1340 - val_mae: 13.2486 - val_mse: 303.1340\n",
      "Epoch 8/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 289.8031 - mae: 12.9643 - mse: 289.8031 - val_loss: 300.2090 - val_mae: 13.1690 - val_mse: 300.2090\n",
      "Epoch 9/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 290.2900 - mae: 12.9471 - mse: 290.2900 - val_loss: 297.9467 - val_mae: 13.1202 - val_mse: 297.9467\n",
      "Epoch 10/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 288.7724 - mae: 12.8760 - mse: 288.7724 - val_loss: 313.5227 - val_mae: 13.3518 - val_mse: 313.5227\n",
      "Epoch 11/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 286.0298 - mae: 12.7999 - mse: 286.0298 - val_loss: 285.7992 - val_mae: 12.8277 - val_mse: 285.7992\n",
      "Epoch 12/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 284.0666 - mae: 12.7829 - mse: 284.0666 - val_loss: 287.2372 - val_mae: 12.8910 - val_mse: 287.2372\n",
      "Epoch 13/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 279.5743 - mae: 12.7133 - mse: 279.5743 - val_loss: 279.4013 - val_mae: 12.6718 - val_mse: 279.4013\n",
      "Epoch 14/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 278.0112 - mae: 12.6318 - mse: 278.0112 - val_loss: 277.1906 - val_mae: 12.6108 - val_mse: 277.1906\n",
      "Epoch 15/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 278.2256 - mae: 12.5868 - mse: 278.2256 - val_loss: 278.1746 - val_mae: 12.5930 - val_mse: 278.1746\n",
      "Epoch 16/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 272.0639 - mae: 12.5159 - mse: 272.0639 - val_loss: 272.1099 - val_mae: 12.5293 - val_mse: 272.1099\n",
      "Epoch 17/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 274.4184 - mae: 12.5349 - mse: 274.4184 - val_loss: 268.2759 - val_mae: 12.3619 - val_mse: 268.2759\n",
      "Epoch 18/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 270.5731 - mae: 12.4728 - mse: 270.5731 - val_loss: 269.2533 - val_mae: 12.4037 - val_mse: 269.2533\n",
      "Epoch 19/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 268.1622 - mae: 12.3955 - mse: 268.1622 - val_loss: 267.7536 - val_mae: 12.4611 - val_mse: 267.7536\n",
      "Epoch 20/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 268.9798 - mae: 12.3871 - mse: 268.9798 - val_loss: 269.8571 - val_mae: 12.4729 - val_mse: 269.8571\n",
      "Epoch 21/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 265.3271 - mae: 12.2556 - mse: 265.3271 - val_loss: 261.8476 - val_mae: 12.2181 - val_mse: 261.8476\n",
      "Epoch 22/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 262.7577 - mae: 12.2487 - mse: 262.7577 - val_loss: 259.1471 - val_mae: 12.1785 - val_mse: 259.1471\n",
      "Epoch 23/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 261.2893 - mae: 12.1951 - mse: 261.2893 - val_loss: 259.6394 - val_mae: 12.2303 - val_mse: 259.6394\n",
      "Epoch 24/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 261.3234 - mae: 12.2094 - mse: 261.3234 - val_loss: 262.7485 - val_mae: 12.1885 - val_mse: 262.7485\n",
      "Epoch 25/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 258.6195 - mae: 12.1107 - mse: 258.6195 - val_loss: 260.5992 - val_mae: 12.2596 - val_mse: 260.5992\n",
      "Epoch 26/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 260.5116 - mae: 12.1475 - mse: 260.5116 - val_loss: 257.4825 - val_mae: 12.0628 - val_mse: 257.4825\n",
      "Epoch 27/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 255.5323 - mae: 11.9975 - mse: 255.5323 - val_loss: 267.3148 - val_mae: 12.2645 - val_mse: 267.3148\n",
      "Epoch 28/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 252.9692 - mae: 11.9635 - mse: 252.9692 - val_loss: 258.4477 - val_mae: 12.1653 - val_mse: 258.4477\n",
      "Epoch 29/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 254.9938 - mae: 12.0135 - mse: 254.9938 - val_loss: 260.3796 - val_mae: 12.2547 - val_mse: 260.3796\n",
      "Epoch 30/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 252.3097 - mae: 11.9501 - mse: 252.3097 - val_loss: 255.6157 - val_mae: 12.0897 - val_mse: 255.6157\n",
      "Epoch 31/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 253.1187 - mae: 11.9494 - mse: 253.1187 - val_loss: 254.5498 - val_mae: 11.9755 - val_mse: 254.5498\n",
      "Epoch 32/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 253.7120 - mae: 11.9923 - mse: 253.7120 - val_loss: 252.6496 - val_mae: 11.8575 - val_mse: 252.6496\n",
      "Epoch 33/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 253.3535 - mae: 11.9318 - mse: 253.3535 - val_loss: 258.8961 - val_mae: 12.2518 - val_mse: 258.8961\n",
      "Epoch 34/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 249.7556 - mae: 11.8613 - mse: 249.7556 - val_loss: 254.4112 - val_mae: 12.1153 - val_mse: 254.4112\n",
      "Epoch 35/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 250.4640 - mae: 11.8837 - mse: 250.4640 - val_loss: 263.0327 - val_mae: 12.2674 - val_mse: 263.0327\n",
      "Epoch 36/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 250.0343 - mae: 11.8657 - mse: 250.0343 - val_loss: 250.5697 - val_mae: 11.9038 - val_mse: 250.5697\n",
      "Epoch 37/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 248.2319 - mae: 11.7930 - mse: 248.2319 - val_loss: 251.1787 - val_mae: 11.8423 - val_mse: 251.1787\n",
      "Epoch 38/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 248.6341 - mae: 11.7908 - mse: 248.6341 - val_loss: 252.9501 - val_mae: 11.8328 - val_mse: 252.9501\n",
      "Epoch 39/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 249.4416 - mae: 11.8218 - mse: 249.4416 - val_loss: 252.1724 - val_mae: 11.8929 - val_mse: 252.1724\n",
      "Epoch 40/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 250.5653 - mae: 11.8506 - mse: 250.5653 - val_loss: 249.9992 - val_mae: 11.8019 - val_mse: 249.9992\n",
      "Epoch 41/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 242.6530 - mae: 11.6547 - mse: 242.6530 - val_loss: 246.2055 - val_mae: 11.6779 - val_mse: 246.2055\n",
      "Epoch 42/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 245.5004 - mae: 11.7360 - mse: 245.5004 - val_loss: 248.2632 - val_mae: 11.7580 - val_mse: 248.2632\n",
      "Epoch 43/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 242.9224 - mae: 11.6168 - mse: 242.9224 - val_loss: 246.9473 - val_mae: 11.8949 - val_mse: 246.9473\n",
      "Epoch 44/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 243.7440 - mae: 11.6562 - mse: 243.7440 - val_loss: 260.9139 - val_mae: 11.7031 - val_mse: 260.9139\n",
      "Epoch 45/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 243.8876 - mae: 11.6560 - mse: 243.8876 - val_loss: 247.1103 - val_mae: 11.8357 - val_mse: 247.1103\n",
      "Epoch 46/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 241.9316 - mae: 11.5761 - mse: 241.9316 - val_loss: 247.3798 - val_mae: 11.8099 - val_mse: 247.3798\n",
      "Epoch 47/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 238.9715 - mae: 11.5049 - mse: 238.9715 - val_loss: 244.6776 - val_mae: 11.6887 - val_mse: 244.6776\n",
      "Epoch 48/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 236.5980 - mae: 11.4441 - mse: 236.5980 - val_loss: 266.6413 - val_mae: 12.4312 - val_mse: 266.6413\n",
      "Epoch 49/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 241.5465 - mae: 11.5728 - mse: 241.5465 - val_loss: 243.5219 - val_mae: 11.7035 - val_mse: 243.5219\n",
      "Epoch 50/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 239.1547 - mae: 11.5126 - mse: 239.1547 - val_loss: 242.0144 - val_mae: 11.5182 - val_mse: 242.0144\n",
      "Epoch 51/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 236.9259 - mae: 11.4558 - mse: 236.9259 - val_loss: 246.9310 - val_mae: 11.4517 - val_mse: 246.9310\n",
      "Epoch 52/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 238.5165 - mae: 11.5048 - mse: 238.5165 - val_loss: 250.4268 - val_mae: 11.9112 - val_mse: 250.4268\n",
      "Epoch 53/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 237.0570 - mae: 11.4462 - mse: 237.0570 - val_loss: 242.7266 - val_mae: 11.5147 - val_mse: 242.7266\n",
      "Epoch 54/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 235.8850 - mae: 11.4190 - mse: 235.8850 - val_loss: 256.3483 - val_mae: 12.1551 - val_mse: 256.3483\n",
      "Epoch 55/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 236.0897 - mae: 11.3952 - mse: 236.0897 - val_loss: 250.0339 - val_mae: 11.8901 - val_mse: 250.0339\n",
      "Epoch 56/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 235.6362 - mae: 11.3539 - mse: 235.6362 - val_loss: 242.2268 - val_mae: 11.6620 - val_mse: 242.2268\n",
      "Epoch 57/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 235.1239 - mae: 11.3771 - mse: 235.1239 - val_loss: 243.8656 - val_mae: 11.7363 - val_mse: 243.8656\n",
      "Epoch 58/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 234.7865 - mae: 11.3817 - mse: 234.7865 - val_loss: 241.5530 - val_mae: 11.5521 - val_mse: 241.5530\n",
      "Epoch 59/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 233.9169 - mae: 11.3287 - mse: 233.9169 - val_loss: 242.4445 - val_mae: 11.5911 - val_mse: 242.4445\n",
      "Epoch 60/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 233.6761 - mae: 11.3363 - mse: 233.6761 - val_loss: 239.5044 - val_mae: 11.4358 - val_mse: 239.5044\n",
      "Epoch 61/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 232.8686 - mae: 11.3107 - mse: 232.8686 - val_loss: 240.0241 - val_mae: 11.4045 - val_mse: 240.0241\n",
      "Epoch 62/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 228.8260 - mae: 11.1945 - mse: 228.8260 - val_loss: 252.3490 - val_mae: 11.3933 - val_mse: 252.3490\n",
      "Epoch 63/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 227.3124 - mae: 11.1424 - mse: 227.3124 - val_loss: 238.6973 - val_mae: 11.5992 - val_mse: 238.6973\n",
      "Epoch 64/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 227.2278 - mae: 11.1684 - mse: 227.2278 - val_loss: 240.4885 - val_mae: 11.5978 - val_mse: 240.4885\n",
      "Epoch 65/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 230.0644 - mae: 11.2180 - mse: 230.0644 - val_loss: 252.2304 - val_mae: 12.0083 - val_mse: 252.2304\n",
      "Epoch 66/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 228.4074 - mae: 11.1882 - mse: 228.4074 - val_loss: 243.5376 - val_mae: 11.6612 - val_mse: 243.5376\n",
      "Epoch 67/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 228.3328 - mae: 11.1538 - mse: 228.3328 - val_loss: 245.0807 - val_mae: 11.8213 - val_mse: 245.0807\n",
      "Epoch 68/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 226.0796 - mae: 11.1259 - mse: 226.0796 - val_loss: 238.0886 - val_mae: 11.5190 - val_mse: 238.0886\n",
      "Epoch 69/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 226.6087 - mae: 11.1150 - mse: 226.6087 - val_loss: 269.1816 - val_mae: 11.6472 - val_mse: 269.1816\n",
      "Epoch 70/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 227.8635 - mae: 11.1443 - mse: 227.8635 - val_loss: 240.5754 - val_mae: 11.6570 - val_mse: 240.5754\n",
      "Epoch 71/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 227.3419 - mae: 11.1520 - mse: 227.3419 - val_loss: 242.1706 - val_mae: 11.2606 - val_mse: 242.1706\n",
      "Epoch 72/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 222.8293 - mae: 11.0104 - mse: 222.8293 - val_loss: 244.7994 - val_mae: 11.3170 - val_mse: 244.7994\n",
      "Epoch 73/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 226.6752 - mae: 11.1227 - mse: 226.6752 - val_loss: 234.7938 - val_mae: 11.3107 - val_mse: 234.7938\n",
      "Epoch 74/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 224.8192 - mae: 11.0692 - mse: 224.8192 - val_loss: 236.7847 - val_mae: 11.4528 - val_mse: 236.7847\n",
      "Epoch 75/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 225.7873 - mae: 11.1030 - mse: 225.7873 - val_loss: 238.3617 - val_mae: 11.2642 - val_mse: 238.3617\n",
      "Epoch 76/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 219.4173 - mae: 10.9045 - mse: 219.4173 - val_loss: 252.1581 - val_mae: 12.0684 - val_mse: 252.1581\n",
      "Epoch 77/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 223.7133 - mae: 11.0287 - mse: 223.7133 - val_loss: 233.7495 - val_mae: 11.2490 - val_mse: 233.7495\n",
      "Epoch 78/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 221.5255 - mae: 10.9549 - mse: 221.5255 - val_loss: 242.8606 - val_mae: 11.6588 - val_mse: 242.8606\n",
      "Epoch 79/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 221.6530 - mae: 10.9866 - mse: 221.6530 - val_loss: 239.4566 - val_mae: 11.4358 - val_mse: 239.4566\n",
      "Epoch 80/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 216.6797 - mae: 10.8472 - mse: 216.6797 - val_loss: 236.7174 - val_mae: 11.3069 - val_mse: 236.7174\n",
      "Epoch 81/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 222.2603 - mae: 10.9873 - mse: 222.2603 - val_loss: 231.2976 - val_mae: 11.1938 - val_mse: 231.2976\n",
      "Epoch 82/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 216.6934 - mae: 10.8238 - mse: 216.6934 - val_loss: 247.8361 - val_mae: 11.9631 - val_mse: 247.8361\n",
      "Epoch 83/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 217.8802 - mae: 10.8786 - mse: 217.8802 - val_loss: 261.6025 - val_mae: 11.3197 - val_mse: 261.6025\n",
      "Epoch 84/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 220.1567 - mae: 10.9420 - mse: 220.1567 - val_loss: 246.0648 - val_mae: 11.6725 - val_mse: 246.0648\n",
      "Epoch 85/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 216.8015 - mae: 10.8551 - mse: 216.8015 - val_loss: 232.1710 - val_mae: 11.3270 - val_mse: 232.1710\n",
      "Epoch 86/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 216.4140 - mae: 10.8204 - mse: 216.4140 - val_loss: 242.0508 - val_mae: 11.3303 - val_mse: 242.0508\n",
      "Epoch 87/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 216.7475 - mae: 10.8355 - mse: 216.7475 - val_loss: 233.2346 - val_mae: 11.3704 - val_mse: 233.2346\n",
      "Epoch 88/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 214.4436 - mae: 10.7430 - mse: 214.4436 - val_loss: 233.2988 - val_mae: 11.2682 - val_mse: 233.2988\n",
      "Epoch 89/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 214.4224 - mae: 10.7374 - mse: 214.4224 - val_loss: 237.1900 - val_mae: 11.1623 - val_mse: 237.1900\n",
      "Epoch 90/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 212.1635 - mae: 10.6783 - mse: 212.1635 - val_loss: 232.0310 - val_mae: 10.9650 - val_mse: 232.0310\n",
      "Epoch 91/100\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 212.8865 - mae: 10.7137 - mse: 212.8865 - val_loss: 256.2822 - val_mae: 12.0366 - val_mse: 256.2822\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_final, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 233.8245 - mae: 11.2203 - mse: 233.8245\n",
      "MAE: 11.181077003479004   MSE: 232.3649139404297\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(X_test_final, y_test)\n",
    "print(\"MAE:\", mae, \"  MSE:\", mse)\n",
    "model.save(\"deep_cluster_attention_model.keras\")\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
